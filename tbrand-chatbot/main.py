import streamlit as st
import os
import queue
import time
# from PyPDF2 import PdfReader
from langchain_core.messages import ChatMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.schema import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, CSVLoader
from dotenv import load_dotenv
from send_sms import send_many
from google_sheet import GoogleSheetsMonitor

ADMIN_PHONE = '01025299685'

load_dotenv()

# ì„ë² ë”© ì´ˆê¸°í™”
@st.cache_resource
def initialize_embeddings():
    return OpenAIEmbeddings(        
        base_url="https://api.platform.a15t.com/v1",
        model="openai/text-embedding-3-small"
    )

# ë¬¸ì„œ ë¡œë” ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
@st.cache_resource
def load_documents(_embedding):
    # ë¬¸ì„œ í´ë” ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”)
    documents_folder = "./documents"
    
    # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    
    # ë¬¸ì„œë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    docs = []
    
    # í´ë” ë‚´ ëª¨ë“  PDF, TXT, CSV íŒŒì¼ ì²˜ë¦¬
    for filename in os.listdir(documents_folder):
        filepath = os.path.join(documents_folder, filename)
        print(f"----------------- Processing file: {filepath}")
        
        # #PDF íŒŒì¼ ì²˜ë¦¬
        # if filename.endswith('.pdf'):
        #     pdf_reader = PdfReader(filepath)
        #     text = ""
        #     for page in pdf_reader.pages:
        #         text += page.extract_text() + "\n"
        #     splits = text_splitter.split_text(text)
        #     docs.extend(splits)
        
        # TXT íŒŒì¼ ì²˜ë¦¬
        if filename.endswith('.txt'):
            with open(filepath, 'r', encoding='utf-8') as f:
                text = f.read()
                splits = text_splitter.split_text(text)
                docs.extend(splits)
        
        # CSV íŒŒì¼ ì²˜ë¦¬
        elif filename.endswith('.csv'):
            print(f"Processing CSV file: {filepath}")
            loader = CSVLoader(filepath)
            docs = loader.load()

            # # Split documents into chunks
            split_docs = text_splitter.split_documents(docs)         
            docs.extend(split_docs)
    
    # ChromaDB ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    DB_PATH = "data/chroma"
    vectorstore = Chroma(    
        embedding_function=_embedding, 
        collection_name="store_faqs", 
        persist_directory=DB_PATH
    )
    vectorstore.reset_collection()
    vectorstore.add_documents(docs)
    #vectorstore.persist()
    return vectorstore

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # ë¬¸ì„œ ì—…ë¡œë“œ ì„¹ì…˜
    st.header("FAQ ìƒì„±")
    #-- 
    select_event = st.sidebar.selectbox('ìë™ ë‹µë³€ì— ì“°ì¼ FAQë¥¼ ë§Œë“¤ ë°©ë²•ì„ ê³ ë¥´ì„¸ìš”',
                                        ['FAQ ë¬¸ì„œ ì—…ë¡œë“œ','í•¸ë“œí° ìŒì„±/ë¬¸ì ê¸°ë°˜ ìë™ ìƒì„±'])

    if select_event == 'FAQ ë¬¸ì„œ ì—…ë¡œë“œ':
        uploaded_files = st.file_uploader(
            "PDF, TXT, CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", 
            type=['pdf', 'txt', 'csv'], 
            accept_multiple_files=True
        )
        
        # ë¬¸ì„œ ì €ì¥ ë²„íŠ¼
        if st.button("ë¬¸ì„œ ì €ì¥", icon="ğŸ“"):
            if uploaded_files:
                # ë¬¸ì„œ ì €ì¥ ê²½ë¡œ
                os.makedirs("./documents", exist_ok=True)
                
                for uploaded_file in uploaded_files:
                    with open(os.path.join("./documents", uploaded_file.name), "wb") as f:
                        f.write(uploaded_file.getbuffer())
                
                with st.spinner("ë¬¸ì„œ ì €ì¥ ì¤‘... ğŸ“"):
                    time.sleep(3)
                # # ë¬¸ì„œ ì—…ë¡œë“œ ì™„ë£Œ í›„ ë²¡í„° ìŠ¤í† ì–´ ì—…ë°ì´íŠ¸    
                # try:
                #     # ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ë‹¤ì‹œ ë¡œë“œ
                #     embeddings = initialize_embeddings()
                #     vectorstore = load_documents(embeddings)
                #     #st.success("DB ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ âœ…")
                # except Exception as e:
                #     st.error(f"ë²¡í„° DB ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ âš ï¸")            
                st.success("ë¬¸ì„œ ì €ì¥ ì™„ë£Œ âœ…")        

    else:    
        # ìŒì„± ë° ë¬¸ì ê°€ì ¸ì˜¤ê¸° ë²„íŠ¼
        phone_number = st.text_input("í•¸ë“œí° ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", value='01025299685')
        # checkbox
        st.checkbox("ìŒì„± ë…¹ìŒ ë°ì´í„°")
        st.checkbox("ë¬¸ì ë©”ì„¸ì§€ ë°ì´í„°") 
        get_data_button = st.button("ë°ì´í„° ê¸°ë°˜ FAQ ìë™ ìƒì„± :robot_face:")
        if get_data_button:
            with st.spinner('Wait for it...'):
                time.sleep(3)
            st.write("ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ âœ…")
        
        
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        # clear_button = st.button("ëŒ€í™” ì´ˆê¸°í™”", icon="ğŸ—‘ï¸")
        # if clear_button:
        #     st.write("ì´ˆê¸°í™” ì™„ë£Œ âœ…")
        #     st.session_state["messages"] = []


# ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ í•¨ìˆ˜
def append_message(role, content):
    st.session_state["messages"].append(ChatMessage(role=role, content=content))
    
def display_messages():
    for message in st.session_state["messages"]:
        st.chat_message(message.role).write(message.content)

def create_sentiment_chain():
    # LLM ì„¤ì •
    llm = ChatOpenAI(        
        base_url="https://api.platform.a15t.com/v1",
        model_name="openai/gpt-4o-2024-08-06",
        temperature=0
    )
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ 'Positive', 'Negative', 'Neutral' ì¤‘ í•˜ë‚˜ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""),
        ("human", "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {text}")
    ])
    
    # ê°ì • ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ í•¨ìˆ˜
    def process_sentiment(response):
        sentiment = response.lower()
        if 'negative' in sentiment:
            return True
        else:
            return False
    
    # ê°ì • ë¶„ì„ ì²´ì¸ êµ¬ì„±
    sentiment_chain = (
        {"text": lambda x: x}
        | prompt 
        | llm 
        | StrOutputParser()
        | process_sentiment
    )
    
    return sentiment_chain

# RAG ì²´ì¸ ìƒì„± í•¨ìˆ˜
def create_rag_chain():
    # ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
    embeddings = initialize_embeddings()
    vectorstore = load_documents(embeddings)
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    # prompt = ChatPromptTemplate.from_messages([
    #     ("system", """ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
    #     ì£¼ì–´ì§„ ë¬¸ë§¥ê³¼ ê´€ë ¨ëœ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ 45ì ì´ë‚´ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë§Œì•½ ë¬¸ì„œì—ì„œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, 'ë‹´ë‹¹ìê°€ í™•ì¸ í›„ì— ë³„ë„ ì•ˆë‚´ ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”."""),
    #     ("human", "ì§ˆë¬¸: {question}\n\në¬¸ë§¥: {context}")
    # ])
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì œê³µëœ ì„¸íƒì†Œ FAQ ë¬¸ì„œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì„¸íƒì†Œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
        ì£¼ì–´ì§„ ë¬¸ë§¥ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ìµœëŒ€í•œ ì‚¬ìš©í•˜ì—¬ 30ì ì´ë‚´ë¡œ ë§¤ìš° ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""),
        ("human", "ì§ˆë¬¸: {question}\n\në¬¸ë§¥: {context}")
    ])
    
    # LLM ì„¤ì •
    llm = ChatOpenAI(        
        base_url="https://api.platform.a15t.com/v1",
        model_name="openai/gpt-4o-2024-08-06",
        temperature=0
    )
    
    # ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜
    def get_retriever_context(question):
        # ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì¡°ê° ì°¾ê¸° (ìƒìœ„ 3ê°œ)
        relevant_docs = vectorstore.similarity_search(question, k=3)
        context = "\n".join([doc.page_content for doc in relevant_docs])
        return context
    
    # RAG ì²´ì¸ êµ¬ì„±
    rag_chain = (
        {"context": get_retriever_context, "question": lambda x: x}
        | prompt 
        | llm 
        | StrOutputParser()
    )
    
    return rag_chain

# í ìƒì„±
input_queue = queue.Queue()
extra_queue = queue.Queue()

st.image('./tbrandchatbot_banner.png', use_container_width=True)

# Streamlit ì•± ì„¤ì • (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
#st.title('T Brand Chatbot :speech_balloon:')

# ì´ì „ ì½”ë“œì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ (initialize_embeddings, load_documents ë“±)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€

# vector store add
def add_documents(doc):
    embeddings = initialize_embeddings()
    DB_PATH = "data/chroma"
    vectorstore = Chroma(    
        embedding_function=embeddings, 
        collection_name="store_faqs", 
        persist_directory=DB_PATH
    )
    if isinstance(doc[0], str) and isinstance(doc[1], str):
        doc = [Document(page_content=doc[0] + "\n" + doc[1])]
        print(f'Add documents: {doc}')
    ids = vectorstore.add_documents(doc)
    #print(vectorstore.get())
    #vectorstore.persist()
    return ids[0] if ids else None  # ì²« ë²ˆì§¸ IDë§Œ ë°˜í™˜
    

def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    
    
    # Google Sheets ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
    sheet_monitor = GoogleSheetsMonitor(
        sheet_key=os.environ['GOOGLE_SHEET_KEY'],
        #sheet_key='1PzERiLTGOCArG2tx8HNaid9z370yq8-hUBf2fELVRzI',  # ì‹¤ì œ Google Sheet í‚¤ë¡œ ëŒ€ì²´
        input_queue=input_queue,
        check_interval=5  # 5ì´ˆë§ˆë‹¤ ì²´í¬
    )
    
    # íì—ì„œ ì…ë ¥ ì²˜ë¦¬
    def process_queue():
        try:
            while True:
                handover = False
                if not input_queue.empty():
                    user_input, phone_number, row_index = input_queue.get_nowait()
                    print(f"Processing input from queue: {user_input}, from Phone Num: {phone_number}, row_index: {row_index}")
                                        
                    # RAG ì²´ì¸ ìƒì„±
                    rag_chain = create_rag_chain()
                    print("rag chain created")
                    try:
                        # ê´€ë¦¬ìê°€ ë‹µë³€ ì¤€ ê²½ìš°ì—
                        if phone_number == ADMIN_PHONE:
                            if "í†µê³„" in user_input or "ëŒ€ì‹œë³´ë“œ" in user_input:
                                send_many(phone_number, "https://bit.ly/3CKvrdR")
                                continue
                            
                            answer = user_input
                            ex_question, ex_phone_number, ex_row_index = extra_queue.get_nowait()
                            print(f"Processing input from extra queue: {ex_question}, from Phone Num: {ex_phone_number}, row_index: {ex_row_index}")
                            
                            # ë‹µë³€ ì „ì†¡
                            send_many(ex_phone_number, answer)
                            print(sheet_monitor.worksheet.update_cell(ex_row_index, 5, answer))
                            new_doc = [ex_question, answer]
                            id = add_documents(new_doc)
                            print("Add documents to vector store. ID: ", id)
                            continue
                        
                        print("rag chain invoked") 
                        
                        st.chat_message("user").write(user_input + " (ê³ ê° : " + phone_number + ")")
                        sentiment_chain = create_sentiment_chain()    
                        # ê°ì • ë¶„ì„ ì‘ë‹µ ìƒì„±
                        is_negative = sentiment_chain.invoke(user_input)
                        print(f"[ê°ì •ë¶„ì„] Q : {user_input}, A : {'Negative' if is_negative else 'Positive'}")
                        if is_negative:
                            msg = "ê³ ê°ê°ì •: ë¶€ì •\n"+ user_input + "\n" + "ê³ ê° : " + phone_number 
                            send_many(ADMIN_PHONE, msg)
                            sheet_monitor.worksheet.update_cell(row_index, 6, "Negative")
                            ai_response = "ê³ ê°ë‹˜ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë‹´ë‹¹ìê°€ ë°”ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤"
                            send_many(phone_number,ai_response)
                            continue
                            
                        
                        if 'ì‚¬ì¥ë‹˜ ì¼ìš”ì¼ ì˜ì—… í•˜ë‚˜ìš”' in user_input:
                            handover = True
                            # handover to admin
                            send_many(ADMIN_PHONE, user_input + "\n" + "(ê³ ê° : " + phone_number + ")")
                            extra_queue.put((user_input, phone_number, row_index))
                            ai_response = "ë‹´ë‹¹ì í™•ì¸ í›„ì— ë³„ë„ ì•ˆë‚´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                            # send message to customer
                            send_many(phone_number, ai_response)
                            
                        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                        if not handover:
                            response = rag_chain.stream(user_input)
                            
                            with st.chat_message("ai"):
                                container = st.empty()
                                ai_response = ""
                                for token in response:
                                    ai_response += token
                                    container.markdown(ai_response)
                        else:
                            with st.chat_message("ai"):
                                container = st.empty()    
                                container.markdown(ai_response)
                        
                        # ë©”ì‹œì§€ ì¶”ê°€
                        append_message("user", user_input)
                        print(sheet_monitor.worksheet.update_cell(row_index, 5, ai_response))
                        append_message("ai", ai_response)
                        send_many(phone_number, ai_response)
                    
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                        #st.error("ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                else:
                    time.sleep(1)
        except Exception as e:
            st.error(f"í ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


    sheet_monitor.start()

    # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    display_messages()    
    st.chat_input('ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”:')

    # íì— ìˆëŠ” ì…ë ¥ ì²˜ë¦¬
    process_queue()   
    
    
# Streamlit ì•± ì‹¤í–‰
if __name__ == "__main__":
    main()
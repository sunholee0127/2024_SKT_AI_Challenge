import streamlit as st
import os
import queue
import time
from PyPDF2 import PdfReader
from langchain_core.messages import ChatMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, CSVLoader
from dotenv import load_dotenv
from send_sms import send_many
from google_sheet import GoogleSheetsMonitor


load_dotenv()

# ì„ë² ë”© ì´ˆê¸°í™”
@st.cache_resource
def initialize_embeddings():
    return OpenAIEmbeddings(        
        base_url="https://api.platform.a15t.com/v1",
        model="openai/text-embedding-3-small"
    )

# ë¬¸ì„œ ë¡œë” ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
@st.cache_resource
def load_documents(_embedding):
    # ë¬¸ì„œ í´ë” ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”)
    documents_folder = "./documents"
    
    # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    
    # ë¬¸ì„œë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    docs = []
    
    # í´ë” ë‚´ ëª¨ë“  PDF, TXT, CSV íŒŒì¼ ì²˜ë¦¬
    for filename in os.listdir(documents_folder):
        filepath = os.path.join(documents_folder, filename)
        
        #PDF íŒŒì¼ ì²˜ë¦¬
        if filename.endswith('.pdf'):
            pdf_reader = PdfReader(filepath)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            splits = text_splitter.split_text(text)
            docs.extend(splits)
        
        # TXT íŒŒì¼ ì²˜ë¦¬
        elif filename.endswith('.txt'):
            with open(filepath, 'r', encoding='utf-8') as f:
                text = f.read()
                splits = text_splitter.split_text(text)
                docs.extend(splits)
        
        # CSV íŒŒì¼ ì²˜ë¦¬
        elif filename.endswith('.csv'):
            loader = CSVLoader(filepath)
            docs = loader.load()

            # # Split documents into chunks
            split_docs = text_splitter.split_documents(docs)         
            docs.extend(split_docs)
    
    # ChromaDB ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    DB_PATH = "data/chroma"
    vectorstore = Chroma(    
        embedding_function=_embedding, 
        collection_name="store_faqs", 
        persist_directory=DB_PATH
    )
    
    vectorstore.add_documents(docs)
    
    return vectorstore

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # ë¬¸ì„œ ì—…ë¡œë“œ ì„¹ì…˜
    st.header("FAQ ë¬¸ì„œ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "PDF, TXT, CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", 
        type=['pdf', 'txt', 'csv'], 
        accept_multiple_files=True
    )
    
    # ë¬¸ì„œ ì €ì¥ ë²„íŠ¼
    if st.button("ë¬¸ì„œ ì €ì¥", icon="ğŸ“"):
        if uploaded_files:
            # ë¬¸ì„œ ì €ì¥ ê²½ë¡œ
            os.makedirs("./documents", exist_ok=True)
            
            for uploaded_file in uploaded_files:
                with open(os.path.join("./documents", uploaded_file.name), "wb") as f:
                    f.write(uploaded_file.getbuffer())
            
            st.success("ë¬¸ì„œ ì €ì¥ ì™„ë£Œ âœ…")
    
    # ë²¡í„° DB ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    if st.button("DB ìƒˆë¡œê³ ì¹¨", icon="ğŸ”„"):
        try:
            # ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ë‹¤ì‹œ ë¡œë“œ
            embeddings = initialize_embeddings()
            vectorstore = load_documents(embeddings)
            st.success("DB ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ âœ…")
        except Exception as e:
            st.error(f"ë²¡í„° DB ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ âš ï¸")
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    clear_button = st.button("ëŒ€í™” ì´ˆê¸°í™”", icon="ğŸ—‘ï¸")
    if clear_button:
        st.write("ì´ˆê¸°í™” ì™„ë£Œ âœ…")
        st.session_state["messages"] = []


# ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ í•¨ìˆ˜
def append_message(role, content):
    st.session_state["messages"].append(ChatMessage(role=role, content=content))
    
def display_messages():
    for message in st.session_state["messages"]:
        st.chat_message(message.role).write(message.content)

# RAG ì²´ì¸ ìƒì„± í•¨ìˆ˜
def create_rag_chain():
    # ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
    embeddings = initialize_embeddings()
    vectorstore = load_documents(embeddings)
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
        ì£¼ì–´ì§„ ë¬¸ë§¥ê³¼ ê´€ë ¨ëœ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ 45ì ì´ë‚´ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë§Œì•½ ë¬¸ì„œì—ì„œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ëª¨ë¥¸ë‹¤ê³  ë‹µë³€í•´ì£¼ì„¸ìš”."""),
        ("human", "ì§ˆë¬¸: {question}\n\në¬¸ë§¥: {context}")
    ])
    
    # LLM ì„¤ì •
    llm = ChatOpenAI(        
        base_url="https://api.platform.a15t.com/v1",
        model_name="openai/gpt-4o-mini-2024-07-18",
        temperature=0
    )
    
    # ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜
    def get_retriever_context(question):
        # ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì¡°ê° ì°¾ê¸° (ìƒìœ„ 3ê°œ)
        relevant_docs = vectorstore.similarity_search(question, k=3)
        context = "\n".join([doc.page_content for doc in relevant_docs])
        return context
    
    # RAG ì²´ì¸ êµ¬ì„±
    rag_chain = (
        {"context": get_retriever_context, "question": lambda x: x}
        | prompt 
        | llm 
        | StrOutputParser()
    )
    
    return rag_chain

# í ìƒì„±
input_queue = queue.Queue()

# Streamlit ì•± ì„¤ì • (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
st.title('T Brand Chat Bot :speech_balloon:')

# ì´ì „ ì½”ë“œì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ (initialize_embeddings, load_documents ë“±)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€

# ë©”ì¸ ì‹¤í–‰ ë¡œì§ ìˆ˜ì •

def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    
    
    # Google Sheets ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
    sheet_monitor = GoogleSheetsMonitor(
        sheet_key='1PzERiLTGOCArG2tx8HNaid9z370yq8-hUBf2fELVRzI',  # ì‹¤ì œ Google Sheet í‚¤ë¡œ ëŒ€ì²´
        input_queue=input_queue,
        check_interval=5  # 5ì´ˆë§ˆë‹¤ ì²´í¬
    )
    
    # íì—ì„œ ì…ë ¥ ì²˜ë¦¬
    def process_queue():
        try:
            while True:
                if not input_queue.empty():
                    user_input, phone_number, row_index = input_queue.get_nowait()
                    
                    print(f"Processing input from queue: {user_input}, from Phone Num: {phone_number}, row_index: {row_index}")
                    st.chat_message("user").write(user_input)
                    
                    try:
                        # RAG ì²´ì¸ ìƒì„±
                        rag_chain = create_rag_chain()
                        
                        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                        response = rag_chain.stream(user_input)
                        
                        with st.chat_message("ai"):
                            container = st.empty()
                            ai_response = ""
                            for token in response:
                                ai_response += token
                                container.markdown(ai_response)
                        
                        # ë©”ì‹œì§€ ì¶”ê°€
                        append_message("user", user_input)
                        append_message("ai", ai_response)
                        print(sheet_monitor.worksheet.update_cell(row_index, 5, ai_response))
                        send_many(phone_number, ai_response)
                        
                
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.error("ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                else:
                    time.sleep(1)
        except Exception as e:
            st.error(f"í ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


    sheet_monitor.start()

    # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    display_messages()    
    st.chat_input('ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”:')

    # íì— ìˆëŠ” ì…ë ¥ ì²˜ë¦¬
    process_queue()   
    
    
# Streamlit ì•± ì‹¤í–‰
if __name__ == "__main__":
    main()